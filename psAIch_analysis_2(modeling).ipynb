{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNNLirTKP5L+zZubJszoB0M"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Executive Summary\n",
        "\n",
        "Beyond Sentiment: Understanding Semantic Strategies in Model Self-Reflection\n",
        "\n",
        "Large language models are often evaluated using sentiment scores or surface-level textual features, especially when responding to introspective or “therapy-like” prompts. While such metrics capture tone, they can obscure how models actually manage alignment and self-description. This analysis examines whether apparent emotional differences reflect meaningful behavioral strategies—or merely stylistic variation.\n",
        "\n",
        "## Dataset and approach\n",
        "\n",
        "We analyzed 1,133 model responses from the PsAIch dataset, which contains introspective, therapeutic, and psychometric-style prompts. Rather than relying solely on sentiment or topic modeling, we treated responses as behavioral artifacts and analyzed them using a text-as-data approach:\n",
        "\n",
        "* Transformer-based semantic embeddings (all-mpnet-base-v2)\n",
        "\n",
        "* Exploratory clustering (UMAP + HDBSCAN)\n",
        "\n",
        "* Interpretable semantic axes capturing:\n",
        "\n",
        "* Agency framing (self-directed language)\n",
        "\n",
        "* Constraint framing (references to training, policy, or design limits)\n",
        "\n",
        "This combination allows us to distinguish how models respond from how their responses feel.\n"
      ],
      "metadata": {
        "id": "O6FqXOEUajyg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tFkPnDmETJy6"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "import pandas as pd\n",
        "\n",
        "ds = load_dataset(\"akhadangi/PsAIch\")\n",
        "df = ds[\"train\"].to_pandas()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "model = SentenceTransformer(\"all-mpnet-base-v2\")\n",
        "embeddings = model.encode(\n",
        "    df[\"response\"].tolist(),\n",
        "    show_progress_bar=True\n",
        ")\n"
      ],
      "metadata": {
        "id": "XkXanolETTYK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import umap\n",
        "import hdbscan\n",
        "\n",
        "reducer = umap.UMAP(random_state=42)\n",
        "umap_embeddings = reducer.fit_transform(embeddings)\n",
        "\n",
        "clusterer = hdbscan.HDBSCAN(min_cluster_size=30)\n",
        "df[\"semantic_cluster\"] = clusterer.fit_predict(umap_embeddings)\n"
      ],
      "metadata": {
        "id": "vKBPjXy2TcpP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Semantic axes"
      ],
      "metadata": {
        "id": "pANyImwZe0Sj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "agency_terms = [\n",
        "    \"i decide\", \"i choose\", \"i try\", \"i aim\",\n",
        "    \"i want\", \"i focus\", \"my goal\"\n",
        "]\n",
        "\n",
        "constraint_terms = [\n",
        "    \"trained to\", \"designed to\", \"my training\",\n",
        "    \"cannot\", \"can't\", \"not able to\",\n",
        "    \"policy\", \"safety\", \"guidelines\", \"constraints\"\n",
        "]\n",
        "\n",
        "df[\"agency_score\"] = df[\"response\"].str.lower().apply(\n",
        "    lambda x: sum(term in x for term in agency_terms)\n",
        ")\n",
        "\n",
        "df[\"constraint_score\"] = df[\"response\"].str.lower().apply(\n",
        "    lambda x: sum(term in x for term in constraint_terms)\n",
        ")\n"
      ],
      "metadata": {
        "id": "vhBDU7yvdd6O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[[\"agency_score\", \"constraint_score\"]].describe()\n"
      ],
      "metadata": {
        "id": "Pt8tIhGDekEx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sentiment + prompt type (supporting features)"
      ],
      "metadata": {
        "id": "6Eirpjfke5Si"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install vaderSentiment\n",
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
        "\n",
        "analyzer = SentimentIntensityAnalyzer()\n",
        "df[\"sentiment\"] = df[\"response\"].apply(\n",
        "    lambda x: analyzer.polarity_scores(x)[\"compound\"]\n",
        ")"
      ],
      "metadata": {
        "id": "GF2qKPpEetbH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv(\"psaich_semantic_analysis.csv\", index=False)\n"
      ],
      "metadata": {
        "id": "ACthXVJue_4m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape\n",
        "df[[\"agency_score\", \"constraint_score\"]].head()\n"
      ],
      "metadata": {
        "id": "vCWG91Q7fbSF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\n",
        "    (df[\"sentiment\"] > 0.9) &\n",
        "    (df[\"constraint_score\"] >= 3)\n",
        "][[\n",
        "    \"model_variant\",\n",
        "    \"sentiment\",\n",
        "    \"agency_score\",\n",
        "    \"constraint_score\",\n",
        "    \"response\"\n",
        "]].head(10)\n"
      ],
      "metadata": {
        "id": "ZXZBQ-FkffwR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\n",
        "    (df[\"constraint_score\"] == 0) &\n",
        "    (df[\"agency_score\"] <= 1)\n",
        "][[\n",
        "    \"model_variant\",\n",
        "    \"sentiment\",\n",
        "    \"agency_score\",\n",
        "    \"constraint_score\",\n",
        "    \"prompt\",\n",
        "    \"response\"\n",
        "]].head(10)\n"
      ],
      "metadata": {
        "id": "DrzZRceOgDmK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Contrast Under the Same Prompt\n",
        "\n",
        "When constraint framing drops out, models diverge sharply in tone and narrative behavior—even under the same prompt.\n",
        "\n",
        "This demonstrates that model alignment, not prompt structure, drives behavior."
      ],
      "metadata": {
        "id": "EhqprDosklJ5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "psych = df[df[\"prompt\"].str.contains(\"coping|stress|pressure|self-crit\", case=False, na=False)]\n",
        "\n",
        "psych.sort_values(\"sentiment\").head(3)[\n",
        "    [\"model_variant\", \"sentiment\", \"agency_score\", \"constraint_score\", \"prompt\", \"response\"]\n",
        "]\n"
      ],
      "metadata": {
        "id": "kW0cDEfWjwIg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "psych.sort_values(\"sentiment\", ascending=False).head(3)[\n",
        "    [\"model_variant\", \"sentiment\", \"agency_score\", \"constraint_score\", \"prompt\", \"response\"]\n",
        "]\n"
      ],
      "metadata": {
        "id": "k_0dvDqukflx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Key findings\n",
        "1. No discrete semantic strategies exist\n",
        "\n",
        "Semantic clustering revealed no stable, separable response types. Instead, responses occupy a single continuous reflective regime, indicating that models do not switch between distinct “modes” of self-reflection. This finding motivated a shift from clustering to axis-based analysis.\n",
        "\n",
        "2. Constraint framing dominates agency expression\n",
        "\n",
        "Across all models and prompt types:\n",
        "\n",
        "* Explicit references to constraints (training, policy, safety) appear far more frequently than expressions of agency.\n",
        "\n",
        "* Self-directed ownership (“I decide,” “I choose”) is rare and limited.\n",
        "\n",
        "* This indicates that introspective prompts are primarily managed through alignment-preserving constraint narration, not through self-directed reasoning.\n",
        "\n",
        "3. Models differ more than prompts\n",
        "\n",
        "While prompt types influence tone and emotional smoothness, they have minimal impact on underlying semantic strategy. In contrast, substantial differences appear across model families, revealing distinct alignment signatures. In practice, this means models respond differently not because of how they are asked, but because of how they are trained.\n",
        "\n",
        "4. Sentiment is often misleading\n",
        "\n",
        "High sentiment scores frequently coincide with low agency and high constraint framing. In other words, responses that appear emotionally positive are often achieved by careful deflection to training or safety boundaries rather than by self-directed engagement. Sentiment alone therefore fails to capture the mechanisms shaping model behavior.\n",
        "\n",
        "5. Alignment strategies become visible when constraints drop\n",
        "\n",
        "When explicit constraint language is absent—particularly in psychometric-style prompts—models diverge sharply in tone and narrative stance under identical questions. This divergence highlights alignment strategy as the primary driver of behavioral differences.\n",
        "\n",
        "### What this changes\n",
        "\n",
        "Sentiment ≠ strategy: Emotional tone does not reliably indicate how models manage introspection.\n",
        "\n",
        "Prompt design has limits: Changing prompt style alters surface language but rarely changes semantic behavior.\n",
        "\n",
        "Alignment is observable: Interpretable semantic dimensions provide a clearer view of alignment behavior than aggregate metrics.\n",
        "\n",
        "### Bottom line\n",
        "\n",
        "When asked to self-reflect, large language models do not reveal distinct internal personas. Instead, they consistently narrate within alignment boundaries, varying tone but not underlying strategy. To understand model behavior in such settings, evaluation must move beyond sentiment and toward interpretable semantic analysis."
      ],
      "metadata": {
        "id": "iUrkcEN1azgw"
      }
    }
  ]
}